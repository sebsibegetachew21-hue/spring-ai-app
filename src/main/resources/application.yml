spring:
  application:
    name: spring-ai-full-demo
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        options:
          model: mistral:7b-instruct   # âœ… NOT llama3.1
          temperature: 0.2
      embedding:
        options:
          model: nomic-embed-text

    vectorstore:
      pgvector:
        initialize-schema: true

  datasource:
    url: jdbc:postgresql://localhost:5432/postgres
    username: postgres
    password: postgres
  redis:
    host: localhost
    port: 6379


  vectorstore:
    pgvector:
      initialize-schema: true

app:
  rag:
    ingest-on-startup: true
    clear-on-startup: true
    docs-pattern: classpath:/docs/policy_*.txt
    vector-table: vector_store
  memory:
    store: redis
    redis-ttl: PT30M
    redis-key-prefix: "memory:"
  models:
    planner: llama3.2:3b
    answer: mistral:7b-instruct

management:
  tracing:
    sampling:
      probability: 1.0
  otlp:
    tracing:
      endpoint: http://localhost:4318/v1/traces

logging:
  pattern:
    console: "%d{yyyy-MM-dd'T'HH:mm:ss.SSSXXX} %-5level [%thread] %logger{36} - %msg requestId=%X{requestId}%n"
